{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV를 이용한 이미지 처리 기초\n",
    "- OpenCV는 컴퓨터로 이미지나 영상을 읽고, 이미지의 사이즈 변환이나 회전, 선분 및 도형 그리\n",
    "기, 채널 분리 등의 연산을 처리할 수 있도록 만들어진 오픈 소스 라이브러리로, 이미지 처리 분야\n",
    "에서 가장 많이 사용된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('resources/lenna.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 크기는 512x512이고 3개 채널로 이루어져 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 픽셀당 8bit이다 (24비트 트루컬러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, method = \"plt\"):\n",
    "    if method == \"plt\":\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    elif method == \"cv2\":\n",
    "        cv2.imshow(\"Image\",img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    elif method == \"colab\":\n",
    "        from google.colab.patches import cv2_imshow\n",
    "        cv2_imshow(img)\n",
    "\n",
    "def show_image_list(title_to_img_dict, figsize):\n",
    "    n = len(title_to_img_dict)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "\n",
    "\n",
    "    for i, (title, img) in enumerate(title_to_img_dict.items()):\n",
    "        axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].set_title(title)\n",
    "        # axes[i].axis('off')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 크기를 리사이즈 할수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "image_small = cv2.resize(img,(100,100))\n",
    "show_image(image_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 상하/좌우로 뒤집을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "image_fliped = cv2.flip(img, 0)\n",
    "show_image(image_fliped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array slicing으로 이미지의 일부 영역을 가져올 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img_sliced = img[100:400, 100:300, :]\n",
    "show_image(img_sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> 이미지의 특정 사각 영역을 전달받은 색상값 fill_color로 채워넣는 cutout함수를 작성하라 (cutout augmentation에 쓰임) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_image(src_img, top_left_corner, bottom_right_corner, fill_color):\n",
    "    \"\"\"\n",
    "    이 함수는 이미지의 사각 영역을 fill_color값으로 채운다. 시작점과 끝점은 top_left_corner, bottom_right_corner 변수에 의해 지정된다.\n",
    "    row -> y축, col -> x축에 대응되며, cv2.imread함수는 dim 0가 y축, dim 1이 x축에 대응됨에 주의할것.\n",
    "    힌트: array slicing을 이용할것\n",
    "\n",
    "    Args:\n",
    "        src_img (numpy.ndarray): The source image to modify.\n",
    "        top_left_corner (tuple): The (row, col) coordinates of the top-left corner of the cutout region.\n",
    "        bottom_right_corner (tuple): The (row, col) coordinates of the bottom-right corner of the cutout region.\n",
    "        fill_color (int or tuple): The color or intensity value to fill the cutout region with. \n",
    "                                   For grayscale images, use an integer value. For RGB images, use a tuple of 3 values.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The modified image with the cutout applied.\n",
    "    \"\"\"\n",
    "\n",
    "    modified_img = src_img.copy() # src_img를 보존하기 위해 deep copy를 수행한다\n",
    "\n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "    \n",
    "    return(modified_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(cutout_image(img, top_left_corner = (50,100), bottom_right_corner = (300, 250), fill_color = (0, 255, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선이나 도형을 그릴 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line_on_image(src_img):\n",
    "    modified_img = src_img.copy()\n",
    "    modified_img = cv2.line(modified_img, pt1 = (100,50), pt2 = (300,200), color = (255,0,0), thickness = 3)\n",
    "    return(modified_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(draw_line_on_image(src_img = img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle_on_image(src_img):\n",
    "    modified_img = src_img.copy()\n",
    "    modified_img = cv2.circle(modified_img, center = (150, 150), radius = 50, color = (0,0,0), thickness = 2)\n",
    "    return modified_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(draw_circle_on_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_poly_on_image(src_img):\n",
    "    modified_img = src_img.copy()\n",
    "\n",
    "    points = np.array([[256, 100], [100, 200], [150, 400], [362, 400]])\n",
    "    \n",
    "    modified_img = cv2.fillPoly(modified_img, [points], color = (255, 255, 255), lineType = 1)\n",
    "    return modified_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(draw_poly_on_image(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine transformation and perspective transformation\n",
    "1. 어파인 변환 (Affine transformation): 점, 직선, 평면을 보존하는 선형 변환으로 변환 전에 평행이였던 선들은 변환 후에도 평행성이 보존된다.\n",
    "\n",
    "$\\begin{pmatrix}x'\\\\y'\\\\ \\end{pmatrix}$ = $\\begin{pmatrix}a&b\\\\c&d\\\\ \\end{pmatrix}$ $\\begin{pmatrix}x\\\\y\\\\ \\end{pmatrix}$ + $\\begin{pmatrix}tx\\\\ty\\\\ \\end{pmatrix}$ \n",
    "\n",
    "2. 원근 변환 (Perspective transformation): 이미지를 다른 관점에서 보는 것처럼 변환한다.\n",
    "\n",
    "$\\begin{pmatrix}x'\\\\y'\\\\w'\\\\ \\end{pmatrix}$ = $\\begin{pmatrix}a&b&c\\\\d&e&f\\\\g&h&1\\\\ \\end{pmatrix}$ $\\begin{pmatrix}x\\\\y\\\\1\\\\ \\end{pmatrix}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(src_img, degree):\n",
    "    \"\"\"\n",
    "    이미지를 degree만큼 회전시킨다.\n",
    "    가장자리는 검은색으로 채워 넣는다\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, channel = src_img.shape\n",
    "    aff_matrix = cv2.getRotationMatrix2D(center = (width/2, height/2), angle = degree, scale = 1)\n",
    "    print(f\"Affine transform matrix is: \")\n",
    "    print(aff_matrix)\n",
    "    img_rotated = cv2.warpAffine(src = src_img, M = aff_matrix, dsize = (width, height), \n",
    "                                 borderValue=(0,0,0))\n",
    "    return(img_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "show_image(rotate_image(img, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform_image(src_img):\n",
    "    ordered_corners = np.array([[57, 630], [936, 330], [1404, 792], [550, 1431]], dtype='float32')\n",
    "\n",
    "    # 너비와 높이 계산\n",
    "    ordered_width = int(max(np.linalg.norm(ordered_corners[0] - ordered_corners[1]), \n",
    "                            np.linalg.norm(ordered_corners[2] - ordered_corners[3]))) \n",
    "    ordered_height = int(max(np.linalg.norm(ordered_corners[0] - ordered_corners[3]), \n",
    "                            np.linalg.norm(ordered_corners[1] - ordered_corners[2])))\n",
    "    # 변환이 될 꼭짓점 좌표 지정\n",
    "    ordered_rect_corners = np.array([[0, 0], [ordered_width, 0], [ordered_width, ordered_height], [0, ordered_height]], dtype='float32')\n",
    "\n",
    "    # 호모그래피 행렬 계산\n",
    "    ordered_scan_matrix = cv2.getPerspectiveTransform(ordered_corners, ordered_rect_corners)\n",
    "    # 원근 변환 다시 적용\n",
    "    ordered_scanned_image = cv2.warpPerspective(src_img, ordered_scan_matrix, (ordered_width, ordered_height))\n",
    "    return(ordered_scanned_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "scan_img = cv2.imread(\"resources/perspective_test.jpg\")\n",
    "transformed_scan_img = perspective_transform_image(scan_img)\n",
    "\n",
    "show_image_list({\"Original image\": scan_img, \n",
    "                 \"Perspective transformed image\" : transformed_scan_img}, \n",
    "                figsize = (10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(src_img, mean = 0, sigma = 1):\n",
    "    gaussian_noise=np.random.normal(mean, sigma, src_img.shape).astype('float32')\n",
    "    \n",
    "    noisy_image = src_img.astype('float32') + gaussian_noise\n",
    "    noisy_image = np.clip(noisy_image, 0, 255)\n",
    "    noisy_image = noisy_image.astype('uint8')\n",
    "    return(noisy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size, sigma=1):\n",
    "    \"\"\"\n",
    "    Generates a Gaussian kernel.\n",
    "    \n",
    "    Args:\n",
    "        size (int): The size of the kernel (should be odd).\n",
    "        sigma (float): The standard deviation of the Gaussian function.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The Gaussian kernel.\n",
    "    \"\"\"\n",
    "    k = (size - 1) // 2\n",
    "    x, y = np.mgrid[-k:k+1, -k:k+1]\n",
    "    normal = 1 / (2.0 * np.pi * sigma**2)\n",
    "    g = np.exp(-((x**2 + y**2) / (2.0 * sigma**2))) * normal\n",
    "    return g / g.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "gaussian_kernel(5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> 커널 사이즈와 표준편차를 전달받아 전달받은 이미지에 가우시안 블러를 적용하는 함수를 작성하라.\n",
    "\n",
    "cv2.filter2D 함수를 이용할것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: `cv2.filter2D(src, ddepth, kernel, ...)`\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    "- **`src`**: 필터를 적용할 소스 이미지.\n",
    "- **`ddepth`**: 출력 이미지의 깊이 (-1일 경우 입력이미지와 동일하게 만듬)\n",
    "- **`kernel`**: 커널로 사용할 2차원 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(src_img, kernel_size=5, sigma=1):\n",
    "    \"\"\"\n",
    "    가우시안 커널을 계산하여 이미지에 적용한다\n",
    "\n",
    "    Args:\n",
    "        src_img (numpy.ndarray): source 이미지\n",
    "        kernel_size (int): 가우시안 커널의 크기 (홀수여야 함).\n",
    "        sigma (float): 가우시안 커널을 계산할때 사용할 표준편자 값\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The blurred image.\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### YOUR CODE START #####\n",
    "\n",
    "\n",
    "    ##### YOUR CODE END #####\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "gray_img = cv2.imread('resources/lenna.png', cv2.IMREAD_GRAYSCALE)\n",
    "noisy_image = add_gaussian_noise(gray_img, mean = 0, sigma = 25)\n",
    "\n",
    "\n",
    "show_image_list({'Original Image': gray_img,\n",
    "                 'Noisy Image': noisy_image,\n",
    "                 'Denoised (σ=1)' : apply_gaussian_blur(noisy_image, 5, 1),\n",
    "                 'Denoised (σ=3)' : apply_gaussian_blur(noisy_image, 9, 3),\n",
    "                 'Denoised (σ=5)' : apply_gaussian_blur(noisy_image, 13, 5),\n",
    "                 },\n",
    "                figsize=(20, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median filter를 사용하면 salt & pepper noise를 효율적으로 제거할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_noise(image):\n",
    "    num_salt = np.ceil(0.05 * image.size)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
    "\n",
    "    salted_image = image.copy()\n",
    "    salted_image[coords[0], coords[1]] = 255\n",
    "    \n",
    "    return salted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pepper_noise(image):\n",
    "    num_pepper = np.ceil(0.05 * image.size)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
    "\n",
    "    peppered_image = image.copy()\n",
    "    peppered_image[coords[0], coords[1]] = 0\n",
    "    return peppered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "salted_img = add_salt_noise(gray_img)\n",
    "peppered_img = add_pepper_noise(salted_img)\n",
    "median_filtered_img = cv2.medianBlur(peppered_img, ksize = 5)\n",
    "\n",
    "show_image_list({'Original Lenna Image': gray_img,\n",
    "                 'Salted Lenna Image': salted_img,\n",
    "                 'Salted & Peppered Lenna' : peppered_img,\n",
    "                 'Median Filtered Lenna' : median_filtered_img,\n",
    "                 },\n",
    "                figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소벨 필터를 이용한 edge 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"resources/sudoku.jpg\")\n",
    "\n",
    "kx = np.array([[-1,0,1], [-2,0,2],[-1,0,1]])\n",
    "ky = np.array([[-1,-2,-1],[0,0,0], [1,2,1]])\n",
    "\n",
    "sobel_x = cv2.filter2D(img, ddepth = -1, kernel = kx) # same with cv2.Sobel(img, ddepth = -1, dx = 1, dy 0, ksize=3)\n",
    "sobel_y = cv2.filter2D(img, ddepth = -1, kernel = ky) # same with cv2.Sobel(img, ddepth = -1, dx = 0, dy = 1, ksize=3) \n",
    "sobel = cv2.addWeighted(sobel_x, 0.5, sobel_y, 0.5, 0)\n",
    "\n",
    "\n",
    "print(\"kernel_x: \")\n",
    "print(kx,\"\\n\")\n",
    "print(\"kernel_y: \")\n",
    "print(ky)\n",
    "show_image_list({'Original Image': img,\n",
    "                 'Sobel_x': sobel_x,\n",
    "                 'Sobel_y' : sobel_y,\n",
    "                 'Sobel merged' : sobel,\n",
    "                 },\n",
    "                figsize=(20, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외에도 다양한 엣지검출기들이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"resources/sudoku.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "blurred_image = cv2.GaussianBlur(img, (5, 5), 1.4)\n",
    "canny_edges = cv2.Canny(blurred_image, threshold1=10, threshold2=50)\n",
    "\n",
    "show_image_list({'Original Image': img,\n",
    "                 'Gaussian Blurred Image': blurred_image,\n",
    "                 'Canny Edge Detection' : canny_edges,\n",
    "                 },\n",
    "                figsize=(20, 6))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
