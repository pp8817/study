{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "이번 실습에서는 아주 깊은 CNN인 Residual Networks를 직접 구현할 예정이다. 일반적으로 아주 깊은 neural network는 아주 복잡한 함수를 학습할 수 있지만 학습이 어렵다.\n",
    "논문 [He et al.](https://arxiv.org/pdf/1512.03385.pdf)이 소개한 Residual Network는 아주 깊은 모델을 학습할 수 있는 방법을 제안하였다.\n",
    "\n",
    "이 실습은 아래 과정으로 이루어진다:\n",
    "- skip connection을 포함한 ResNets의 기본 building block을 pytorch로 직접 구현한다.\n",
    "- building block을 쌓아 resnet을 직접 구현하고 이미지 분류를 시도한다.\n",
    "- pre-trained model을 이용하여 transfer learning을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "\n",
    "import wandb\n",
    "\n",
    "from training_utilities import train_loop, evaluation_loop, create_dataloaders, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem of Very Deep Neural Networks\n",
    "\n",
    "최근 neural network는 점점더 깊어지고 있으며 AlexNet이 몇개의 layer만 가졌다면 최신 neural network는 수백개의 layer들로 이루어진다.\n",
    "\n",
    "* 깊은 네트워크의 가장 중요한 장점은 아주 복잡한 함수도 학습할 수 있다는 것이다. 따라서 edges와 같이 간단한 feature부터 아주 복잡한 features까지 다양한 층위의 feature들을 학습할 수 있다\n",
    "\n",
    "* 하지만 신경망이 깊어지는것이 항상 좋은 결과를 만드는 것은 아니다. 가장 큰 어려움은 vanishing gradients로, 깊은 신경망에서 gradient값이 아주 빨리 0에 가까워져 학습이 아주 느려지는 것이다.\n",
    "\n",
    "* 좀더 구체적으로는 backpropagate이 마지막 레이어(layer)부터 첫번째 레이어까지 진행되는 과정에서, weight matrix가 계속해서 곱해지며 따라서 gradient값이 기하급수적으로 빠르게 0으로 수렴한다. (또는 아주 드물게 gradient값이 기하급수적으로 증가하여 gradient explode가 발생하기도 함). \n",
    "\n",
    "* 따라서 아래와 같이 학습과정에서 얕은 layer의 gradient의 크기(norm)가 빠르게 0으로 감소하는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"resources/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\"></center>\n",
    "<caption><center> <u> <b>Figure</b> </u>  : <b>Vanishing gradient</b> <br> 얕은 레이어에서 학습 속도가 아주 빠르게 감소한다 </center></caption>\n",
    "\n",
    "\n",
    "이러한 문제를 ResNet을 통해 해결할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Residual Network\n",
    "\n",
    "ResNets 에서는 \"shortcut\" 또는 \"skip connection\" 을 통해 레이어를 스킵할수 있도록 해준다.\n",
    "\n",
    "<center><img src=\"resources/skip_connection_kiank.png\" style=\"width:650px;height:200px;\"></center>\n",
    "<caption><center> <u> <b>Figure</b> </u>  : skip-connection <br> </center></caption>\n",
    "\n",
    "왼쪽 이미지는 신경망의 \"main path\"를 보여준다. 오른쪽의 이미지는 shortcut를 추가한 것이다. \n",
    "이러한 ResNet blocks 쌓음으로써 아주 깊은 신경망을 학습할 수 있다.\n",
    "\n",
    "shortcut이 있는 ResNet block은 항등함수(identity function)를 학습하기 아주 쉬워진다 (모든 weight가 0이면 항등함수).  이는 이 ResNet block을 쌓는것으로 인한 성능 저하가 거의 없을 것임을 의미한다.  \n",
    "    \n",
    "그런 측면에서 ResNet이 항등 함수를 배우기 쉬운 것으로 인한 효과가 skip connection으로 vanishing gradients문제를 완화하는 것으로 인한 효과보다 더 크다는 보고들도 존재한다.\n",
    "\n",
    "ResNet에는 input과 output의 차원이 같은지 다른지에 따라 \"identity block\", \"convolutional block\" 이렇게 크게 두가지 종류의 block이 존재한다. 각각을 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Identity Block\n",
    "\n",
    "identity block은 ResNet의 기본 블럭으로, 입력 activation(예 $a^{[l]}$)와 출력 activation (예 $a^{[l+2]}$)이 같은 차원일때 사용된다.\n",
    "\n",
    "<center><img src=\"resources/idblock2_kiank.png\" style=\"width:650px;height:150px;\"></center>\n",
    "<caption><center> <u> <b>Figure</b> </u> : <b>2개의 레이어를 건너뛰는 Identity block.</b> </center></caption>\n",
    "\n",
    "학습 속도를 향상시키기 위한 BatchNorm 레이어가 포함되어 있다.\n",
    "\n",
    "이 블럭은 ResNet18, ResNet34에서 사용되며,\n",
    "\n",
    "ResNet50부터는 이보다 더 효과적인 3개의 hidden layer를 건너뛰는 identity block을 사용한다\n",
    "\n",
    "<center><img src=\"resources/idblock3_kiank.png\" style=\"width:650px;height:150px;\"></center>\n",
    "    <caption><center> <u> <b>Figure</b> </u>  : <b>3개의 레이어를 건너뛰는 Identity block.</b> </center></caption>\n",
    "\n",
    "좀더 구체적으로는 아래 그림의 우측과 같이 Bottleneck block이라고도 불리는 구조를 사용하며 1x1 conv를 통해 필터 수를 줄여 3x3 conv를 수행하고 다시 늘림으로써 layer의 수는 더 많아졌지만 computation은 줄어들어 더 효율적이며 non-linearity도 많아졌다.\n",
    "\n",
    "<center><img src=\"resources/Basic Block_1.png\" style=\"width:264px;\">  <img src=\"resources/Bottleneck Block_2.png\" style=\"width:300px;\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> Identity block을 구현하라\n",
    "\n",
    "1. main path의 첫번째 layer\n",
    "- 첫번째 Conv2d는 ``intermediate_channels``개의 1x1 필터와 stride = 1, \"valid\" padding으로 이루어져 있다. BatchNorm을 수행할 것이므로 bias = False이다.\n",
    "- BatchNorm은 'channels'축으로 데이터를 normalize한다.\n",
    "- 그 후 ReLU activation function을 적용한다 (hyperparameter는 없음)\n",
    "\n",
    "2. main path의 두번쨰 layer\n",
    "- 두번째 Conv2d는 ``intermediate_channels``개의 3x3 필터와 stride = 1, \"same\" padding으로 이루어져 있다. (conv후 이미지 크기가 같음). bias = False이다.\n",
    "- BatchNorm\n",
    "- ReLu\n",
    "\n",
    "3. main path의 세번째 layer\n",
    "- 세번째 Conv2d는 ``intermediate_channels`` x ``expansion``개의 1x1 필터와 stride = 1, \"valid\" padding으로 이루어져 있다. bias = False이다.\n",
    "- BatchNorm\n",
    "- ReLU activation은 **없다**\n",
    "\n",
    "4. Shortcut path\n",
    "- Conv의 결과와 입력값이 더해진다\n",
    "- 그 후 ReLU activation을 취한다.\n",
    "\n",
    "아래 documentation을 참고하여 구현하라.\n",
    "- [Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) : 만약 모델이 eval모드일 경우 weight가 업데이트 되지 않는다. \n",
    "- [ReLu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, intermediate_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Convolutional Block\n",
    "\n",
    "ResNet \"convolutional block\"은 두번쨰 형태의 블럭으로 input과 output차원이 맞지 않을때 사용할 수 있다. indentity block과의 차이는 shortcut path에 Conv2D레이어가 존재한다는 것이다\n",
    "\n",
    "<center><img src=\"resources/convblock_kiank.png\" style=\"width:650px;height:150px;\"></center>\n",
    "<caption><center> <b>Convolutional block</b> </center></caption>\n",
    "\n",
    "* shortcut path의 Conv2D레이어는 입력 $x$를 다른 차원으로 매핑하여 main path의 출력값과 일치시키는데 사용된다.\n",
    "* 예를들어 공간 차원의 height와 width를 1/2로 줄이려면 1x1 convolution을 stride = 2로 수행한다. \n",
    "* 이 Conv2D 레이어는 non-linear activation 함수를 적용하지 않는다. 주된 목적이 입력 차원을 줄이는 선형 함수를 학습하는 것이기 때문이다.\n",
    "\n",
    "\n",
    "<mark>과제</mark> Convolution Block을 구현하라\n",
    "\n",
    "1. main path의 첫번째 레이어\n",
    "- 첫번째 Conv2d는 `intermediate_channels`개의 1x1 필터와 stride = 1, \"valid\" padding, bias = False이다.\n",
    "- BatchNorm\n",
    "- ReLU activation\n",
    "\n",
    "2. main path의 두번째 레이어\n",
    "- 두번째 Conv2d는 `intermediate_channels`개의 3x3필터와 stride = stride, padding = 1, bias = False이다.\n",
    "- BatchNorm\n",
    "- ReLU activation\n",
    "\n",
    "3. main path의 세번째 레이어\n",
    "- 세번째 Conv2d는 ``intermediate_channels`` x ``expansion``개의 1x1 필터와 stride = 1, \"valid\" padding, bias = False이다.\n",
    "- BatchNorm\n",
    "- ReLU activation\n",
    "- **No** ReLU activation \n",
    "\n",
    "4. Shortcut path\n",
    "- shortcut path의 Conv2d는 ``intermediate_channels`` x ``expansion``개의 1x1 필터와 stride = stride, \"valid\" padding, bias = False이다.\n",
    "- BatchNorm\n",
    "\n",
    "5. Final step: \n",
    "- shortcut과 main path의 값을 더한다\n",
    "- ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, intermediate_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your ResNet Model (50 layers)\n",
    "\n",
    "이제 ResNet50을 쌓기위한 블럭이 모두 완성되었다. 아래 그림은 ResNet구조를 나타내며, \"ID BLOCK\"은 Identity block을, \"ID BLOCK x3\"은 identity block을 3개 쌓는것을 의미한다.\n",
    "\n",
    "<center><img src=\"resources/resnet_kiank.png\" style=\"width:850px;height:150px;\"></center>\n",
    "<caption><center> <b>ResNet-50 model</b> </center></caption>\n",
    "\n",
    "<mark>과제</mark> 50개의 레이어가 있는 ResNet50 모델을 구현하라.\n",
    "ResNet-50 모델은 아래와 같이 이루어져 있다.\n",
    "- Stage 1 (Stem):\n",
    "    - 64개의 7x7 필터를 가지고 stride = 2, padding = 3인 Conv2D레이어 (bias=False)\n",
    "    - BatchNorm\n",
    "    - ReLU activation\n",
    "    - stride = 2, kernel_size = 3, padding = 1인 MaxPool2d\n",
    "- Stage 2 (3 layer):\n",
    "    - intermediate_channels = 64, expansion = 4, stride = 1인 convolutional block \n",
    "    - intermediate_channels = 64, expansion = 4인 2개의 identity block\n",
    "- Stage 3 (4 layer):\n",
    "    - intermediate_channels = 128, expansion = 4, stride = 2인 convolutional block \n",
    "    - intermediate_channels = 128, expansion = 4인 3개의 identity block\n",
    "- Stage 4 (6 layer):\n",
    "    - intermediate_channels = 256, expansion = 4, stride = 2인 convolutional block \n",
    "    - intermediate_channels = 256, expansion = 4인 5개의 identity block\n",
    "- Stage 5 (3 layer):\n",
    "    - intermediate_channels = 512, expansion = 4, stride = 2인 convolutional block \n",
    "    - intermediate_channels = 512, expansion = 4인 2개의 identity block\n",
    "- AdaptiveAvgPool2d를 이용한 2D Average Pooling (output = 1x1)\n",
    "- Flatten layer\n",
    "- Linear (Fully Connected) 레이어 (out_features = num_classes)\n",
    "\n",
    "아래 문서를 참조할것\n",
    "- [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
    "- [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "- [flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html)\n",
    "- [AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##### YOUR CODE START #####\n",
    "\n",
    "        ##### YOUR CODE END #####\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model = ResNet50(1000)\n",
    "print(f\"# of parameters of your ResNet50 model: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접 구현한 resnet과 PyTorch에 미리 구현되어있는 resnet의 파라미터 수가 같음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "torch_model = models.resnet50()\n",
    "print(f\"# of parameters of pre-implemented model: {sum(p.numel() for p in torch_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 resnet을 이용하여 CIFAR-10 데이터셋을 학습해보자.\n",
    "\n",
    "CIFAR-10은 32x32x3의 해상도의 사물 데이터를 모아 놓은 데이터 세트로, 비행기(airplane), 자동차(automobile), 새(bird), 고양이(cat) 등 총 10개의 클래스로 구성된다.\n",
    "\n",
    "학습 데이터는 50,000개이고, 테스트 데이터는 10,000개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_datasets(data_root_dir):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "    ])\n",
    "\n",
    "    # Load CIFAR-10 dataset\n",
    "    train_dataset = datasets.CIFAR10(root=data_root_dir, train=True, download=True, transform=train_transforms)\n",
    "    test_dataset = datasets.CIFAR10(root=data_root_dir, train=False, download=True, transform=test_transforms)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_few_samples(dataset, cols=8, rows=5):\n",
    "    label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']  # CIFAR10 class names\n",
    "\n",
    "    figure, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2)) \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(cols * rows):\n",
    "        sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "        img, label = dataset[sample_idx]\n",
    "        img = img.permute(1, 2, 0)  # CHW to HWC\n",
    "        img = img.numpy()  # Convert to numpy array\n",
    "        img = (img * 0.5 + 0.5)  # Unnormalize to [0,1] for display\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(label_names[label])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = load_cifar10_datasets(\"/datasets\")\n",
    "visualize_few_samples(train_dataset, cols = 5, rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 128) \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # gives (8, 14, 14)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # gives (16, 5, 5)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark> ResNet50으로 CIFAR10 데이터셋을 학습하고 지난시간에 구현한 SimpleCNN 모델과 성능을 비교하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes, config):\n",
    "    if model_name == \"resnet50\":\n",
    "        model = ResNet50(num_classes)\n",
    "    elif model_name == \"SimpleCNN\":\n",
    "        model = SimpleCNN()\n",
    "    else:\n",
    "        raise Exception(\"Model not supported: {}\".format(model_name))\n",
    "    print(f\"Using model {model_name} with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(config):\n",
    "    ## data and preprocessing settings\n",
    "    data_root_dir = config['data_root_dir']\n",
    "    num_worker = config.get('num_worker', 4)\n",
    "\n",
    "    ## Hyper parameters\n",
    "    batch_size = config['batch_size']\n",
    "    learning_rate = config['learning_rate']\n",
    "    start_epoch = config.get('start_epoch', 0)\n",
    "    num_epochs = config['num_epochs']\n",
    "\n",
    "    ## checkpoint setting\n",
    "    checkpoint_save_interval = config.get('checkpoint_save_interval', 10)\n",
    "    checkpoint_path = config.get('checkpoint_path', \"checkpoints/checkpoint.pth\")\n",
    "    best_model_path = config.get('best_model_path', \"checkpoints/best_model.pth\")\n",
    "    load_from_checkpoint = config.get('load_from_checkpoint', None)\n",
    "\n",
    "    ## variables\n",
    "    best_acc1 = 0\n",
    "\n",
    "    ## set learning deterministic\n",
    "    # torch.manual_seed(1)\n",
    "\n",
    "    wandb.init(\n",
    "        project=config[\"wandb_project_name\"],\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    train_dataset, test_dataset = load_cifar10_datasets(data_root_dir)\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    \n",
    "    train_dataloader, test_dataloader = create_dataloaders(train_dataset, test_dataset, device, \n",
    "                                                           batch_size = batch_size, num_worker = num_worker)\n",
    "\n",
    "\n",
    "    model = get_model(model_name = config[\"model_name\"], num_classes= num_classes, config = config).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    if load_from_checkpoint:\n",
    "        load_checkpoint_path = (best_model_path if load_from_checkpoint == \"best\" else checkpoint_path)\n",
    "        start_epoch, best_acc1 = load_checkpoint(load_checkpoint_path, model, optimizer, device)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loop(model, device, train_dataloader, criterion, optimizer, epoch)\n",
    "        acc1 = evaluation_loop(model, device, test_dataloader,criterion, epoch)\n",
    "\n",
    "\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if (epoch + 1) % checkpoint_save_interval == 0 or is_best:\n",
    "            save_checkpoint(checkpoint_path, model, optimizer, epoch, best_acc1, is_best, best_model_path)\n",
    "\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_root_dir': '/datasets',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "    'num_epochs': 10,\n",
    "    'model_name': 'resnet50',\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    'wandb_project_name': 'CIFAR10_train',\n",
    "\n",
    "    \"checkpoint_save_interval\" : 10,\n",
    "    \"checkpoint_path\" : \"checkpoints/checkpoint.pth\",\n",
    "    \"best_model_path\" : \"checkpoints/best_model.pth\",\n",
    "    \"load_from_checkpoint\" : None,    # Options: \"latest\", \"best\", or None\n",
    "}\n",
    "train_main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning을 위해서는 먼저 dataset transform을 사전학습된 모델의 transform과 일치시켜야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_datasets(data_root_dir):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])  # pretraining에서 사용한 normalize로 수정\n",
    "    \n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # pretraining에서 사용된 이미지 사이즈로 수정\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # pretraining에서 사용된 이미지 사이즈로 수정\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_root_dir, train=True, download=True, transform=train_transforms)\n",
    "    test_dataset = datasets.CIFAR10(root=data_root_dir, train=False, download=True, transform=test_transforms)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 PyTorch에서 제공하는 pre-trained model의 weight를 가져올 수 있다.\n",
    "\n",
    "PyTorch에서 제공하는 다른 pre-trained model들은 [링크](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights)를 참조하기 바람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(weights = 'IMAGENET1K_V2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 모델의 구조를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:<35} {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning을 위해서는 두가지가 필요하다.\n",
    "1. 마지막 레이어의 logit 출력 차원을 데이터셋에 적합하게 수정 (out_features = 10 for CIFAR10 dataset)\n",
    "2. 학습할 layer를 설정\n",
    "\n",
    "아래와 같은 코드를 통해 마지막 레이어인 fc layer를 수정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 코드를 통해 학습하고자 하는 파라미터를 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:<30} Param shape: {str(param.shape):<30} requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>과제</mark>\n",
    "아래 코드를 완성하여 CIFAR10데이터셋에 대한 transfer learning을 수행하라.\n",
    "\n",
    "`fc` 와 `layer4`만 학습하고 나머지 파라미터는 동결시킬것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, num_classes, config):\n",
    "    if model_name == \"resnet50\":\n",
    "        if config.get('pretrained', \"\"): #if pretrained model name is given\n",
    "            print(f'Using pretrained model {config[\"pretrained\"]}')\n",
    "            model = models.resnet50(weights = config[\"pretrained\"])\n",
    "\n",
    "            ##### YOUR CODE START #####\n",
    "\n",
    "            ##### YOUR CODE END #####\n",
    "                \n",
    "        else:\n",
    "            model = models.resnet50()\n",
    "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == \"SimpleCNN\":\n",
    "        model = SimpleCNN()\n",
    "    else:\n",
    "        raise Exception(\"Model not supported: {}\".format(model_name))\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Using model {model_name} with {total_params} parameters ({trainable_params} trainable)\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_root_dir': '/datasets',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-3,\n",
    "    'num_epochs': 10,\n",
    "    'model_name': 'resnet50',\n",
    "    'pretrained' : 'IMAGENET1K_V2',\n",
    "    \"dataset\": \"CIFAR10\",\n",
    "    'wandb_project_name': 'CIFAR10_train',\n",
    "\n",
    "    \"checkpoint_save_interval\" : 10,\n",
    "    \"checkpoint_path\" : \"checkpoints/checkpoint.pth\",\n",
    "    \"best_model_path\" : \"checkpoints/best_model.pth\",\n",
    "    \"load_from_checkpoint\" : None,    # Options: \"latest\", \"best\", or None\n",
    "}\n",
    "train_main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
